{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vignette on using EpiClass\n",
    "\n",
    "This notebook will cover:\n",
    "\n",
    "1. Brief overview of EpiClass\n",
    "\n",
    "\n",
    "2. Overview of **generating methylation density tables** from either bisulfite sequencing data or DNA melt data (obtained from DREAMing assay: https://doi.org/10.1093/nar/gkv795)\n",
    "<p style=\"color:red;\"> A. Sequencing\n",
    "<p style=\"color:red;\"> B. DREAMing\n",
    "    \n",
    "    \n",
    "3. Generate figures for the EpiClass manuscript\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overview of EpiClass:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is it?\n",
    "\n",
    "EpiClass is a software program to distinguish case samples from control samples using **methylation density profiles** of each sample.\n",
    "\n",
    "This was built primarily from the standpoint of liquid biopsies, in which \"*cases*\" are plasma samples from patients with cancer and \"*controls*\" are plasma samples from otherwise healthy individuals. \n",
    "\n",
    "##### The problem:\n",
    "Here, the assumption is that DNA fragments released from tumors (circulating tumor DNA, i.e., ctDNA) are present in the plasma from patients with cancer, but ctDNA can be highly diluted in the overall circulating cell-free DNA (cfDNA) pool. The majority of cfDNA fragments are assumed to be released from other noncancerous cells, the majority being white blood cells. Can we identify differences in the cfDNA from patients with cancer compared to healthy individuals that are due to the presence of ctDNA?\n",
    "\n",
    "##### The strategy:\n",
    "Tumors have differentially methylated regions of the genome with respect to noncancerous tissues. Our goal is to look for these differences in the collected cfDNA pool and use this information to decide if a sample is from a patient with cancer or not. We do this by looking at the cfDNA pool at specific genomic loci of interest, e.g., ones that have been identified as being differentially methylated in cancer. Specifically, we look at the **methylation density profiles** of our sample cohorts and use these to generate **optimal cutoffs for classifying them**.\n",
    "\n",
    "These cutoffs and the predicted classsification performances are a primary output of EpiClass. These cutoffs can be used to predict the classification performance of currently existing DNA methylation biomarkers but can also be used to refine lists of, and guide the development of, putative methylation biomarkers in a liquid biopsy (or similar setting). Additionally, EpiClass can return a variety of different visualizations to help users understand the underlying **intramolecular DNA methylation heterogeneity** of their samples.\n",
    "\n",
    "\n",
    "### What it a methylation density profile?\n",
    "\n",
    "EpiClass uses data that has DNA methylation information of individual DNA molecules. This can be sequencing data but can also be data generated from high resolution DNA melt technologies that can measure the methylation density of individual DNA fragments.\n",
    "\n",
    "**The methylation density** is simply the number of methylated CpG sites out of total CpG sites contained within an individual DNA fragment. So here, we define it as an **intramolecular** feature.\n",
    "\n",
    "A methylation density profile is a tabularized count of the number of **epialleles** (DNA fragments with different methylation patterns) in a sample with different **methylation densities**. This is within the context of a specific genomic window or locus. \n",
    "\n",
    "EpiClass only cares about the methylation densitites of each individual DNA fragment and not the methylation pattern information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generating methylation density tables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The first step of EpiClass is to generate a methylation density table for a group of samples.\n",
    "These can be samples designated as cases or controls or both. However, any comparison between cases and controls requires both sample cohorts to be recorded in the sample methylation density table.\n",
    "\n",
    "###### Each given methylation density table is for a specific genomic interval/region of interest.\n",
    "Note that different genomic intervals or regions can be used to construct the table, but this means that all reads are combined and tabularized for each sample. The actual genomic locations of the reads, after being selected, are not considered. This means that if multiple regions are selected to pull reads from to make the table, they will all be considered as one \"concatenated region\". It's probably best to look at one contiguous genomic region at a time. Each one of these will have its own methylation density table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> A. Methylation density table from sequencing data\n",
    "```\n",
    "epiclass READtoMD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T17:18:52.535589Z",
     "start_time": "2019-12-06T17:18:52.531075Z"
    }
   },
   "source": [
    "##### Methylation density tables can be generated from aligned sequencing BAM/SAM files.\n",
    "Each sample methylation density profile in the table will be generated from the sample BAM/SAM.\n",
    "\n",
    "##### The alignment files are generated by Bismark\n",
    "https://www.bioinformatics.babraham.ac.uk/projects/bismark/\n",
    "\n",
    "The important information for each alignment in the BAM file is the **XM:** field.\n",
    "\n",
    "Example general commands for bismark paired end read alignment:\n",
    "```\n",
    "trim_galore --fastqc --gzip --cores 4 --paired sample_1.fq.gz sample_2.fq.gz\n",
    "\n",
    "bismark --bowtie2 --dovetail --non_bs_mm --multicore 4 --nucleotide_coverage --genome genomes/ENSEMBL_GRCh37 -1 sample_1_val_1.fq.gz -2 sample_2_val_2.fq.gz\n",
    "\n",
    "mv sample_1_val_1_bismark_bt2_pe.bam sample.orig.bam\n",
    "\n",
    "# filter poorly converted reads\n",
    "filter_non_conversion -p sample.orig.bam\n",
    "mv sample.orig.nonCG_filtered.bam sample.filt.bam\n",
    "\n",
    "# sort bam\n",
    "sortedBam=sample.sorted.bam\n",
    "samtools sort sample.filt.bam > $sortedBam\n",
    "samtools index sample.filt.bam\n",
    "```\n",
    "\n",
    "\n",
    "##### BAM/SAM files should be stored in a separate subdirectory\n",
    "```\n",
    "/testSamples/testCases\n",
    "/testSamples/testControls\n",
    "```\n",
    "\n",
    "##### The genomic interval(s) of interest needs to be indicated\n",
    "Can explicity define a single contiguous interval with:\n",
    "```\n",
    "chr19:58220244-58220744\n",
    "```\n",
    "Or define multiple intervals in a bed file:\n",
    "```\n",
    "exampleBedIntervals.txt\n",
    "\n",
    "chr19\t58220244\t58220744\n",
    "chr10\t102894793\t102895293\n",
    "chr18\t74961883\t74962383\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The command (from the command line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T17:30:54.742017Z",
     "start_time": "2019-12-06T17:30:54.327417Z"
    }
   },
   "source": [
    "```\n",
    "epiclass READtoMD -i /testSamples/ --intervals chr19:58220244-58220744 > log.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard output can be collected and will look something like this:\n",
    "```\n",
    "cat log.txt\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------\n",
    "Time:2019-12-06_12-39\n",
    "#--------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------\n",
    "Command:\n",
    "['/miniconda3/envs/epiclass/bin/epiclass', 'READtoMD', '-i', 'testSamples/', '--intervals', 'chr19:58220244-58220744']\n",
    "Args:\n",
    "Namespace(cmd='READtoMD', fileTag=None, fileType=None, input='testSamples/', intervals='chr19:58220244-58220744', output=None, overlap=0.0, slice=False, verbose=0)\n",
    "#--------------------------------------------------------------------------\n",
    "READtoMD:\n",
    "Converting files in testSamples/ to methylation density table READtoMD.DT.2019-12-06_12-39.csv.\n",
    " \n",
    "extracting reads from: case_1.bam\n",
    " 180 unique sequences containing CpGs in chr19:58220244-58220744\n",
    " 180 total unique sequences containing CpGs\n",
    " \n",
    "extracting reads from: case_10.bam\n",
    " 202 unique sequences containing CpGs in chr19:58220244-58220744\n",
    " 202 total unique sequences containing CpGs\n",
    " \n",
    "extracting reads from: case_11.bam\n",
    " 180 unique sequences containing CpGs in chr19:58220244-58220744\n",
    " 180 total unique sequences containing CpGs\n",
    "\n",
    "...\n",
    "...\n",
    "...\n",
    "\n",
    "extracting reads from: control_8.bam\n",
    " 53 unique sequences containing CpGs in chr19:58220244-58220744\n",
    " 53 total unique sequences containing CpGs\n",
    " \n",
    "extracting reads from: control_9.bam\n",
    " 50 unique sequences containing CpGs in chr19:58220244-58220744\n",
    " 50 total unique sequences containing CpGs\n",
    " \n",
    "Cleaning table...\n",
    "\n",
    "READtoMD.DT.2019-12-06_12-39.csv created.\n",
    " \n",
    "READtoMD complete.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The READtoMD methylation density table will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:39:25.288844Z",
     "start_time": "2019-12-06T21:39:25.131765Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'testSamples/testSampleOutput/READtoMD.DT.2019-12-06_12-39.csv' does not exist: b'testSamples/testSampleOutput/READtoMD.DT.2019-12-06_12-39.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-afe60fdfd0cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'testSamples/testSampleOutput/READtoMD.DT.2019-12-06_12-39.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'testSamples/testSampleOutput/READtoMD.DT.2019-12-06_12-39.csv' does not exist: b'testSamples/testSampleOutput/READtoMD.DT.2019-12-06_12-39.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('testSamples/testSampleOutput/READtoMD.DT.2019-12-06_12-39.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns:\n",
    "\n",
    "1. chr -> chromosome of selected interval\n",
    "***\n",
    "2. interval_start --> start of selected interval\n",
    "***\n",
    "3. end of selected interval\n",
    "***\n",
    "4. methSeqStart --> actual start of the read/read-pair\n",
    "***\n",
    "5. methSeqStop --> actual stop of the read/read-pair\n",
    "***\n",
    "6. methSeqLength --> length covered by the read/read-pair. Note that these are paired end reads, so this length includes the length of each read/read-pair plus the insert size.\n",
    "***\n",
    "7. numU --> number of unmethylated CpG sites covered by the read/read-pair (but not by the insert)\n",
    "***\n",
    "8. numM --> number of methylated CpG sites covered by the read/read-pair (but not by the insert)\n",
    "***\n",
    "9. MD --> the determined methylatio density of the read/read-pair (numM / numM + numU)\n",
    "***\n",
    "Remaining columns are the methylation density profiles of each sample. The counts in each column cell are the number of read/read-pairs with the given coordinates, numU, numM, and MD metrics.\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T18:32:15.957701Z",
     "start_time": "2019-12-06T18:32:15.952297Z"
    }
   },
   "source": [
    "### <p style=\"color:red;\"> B. Methylation density table from DREAMing melt data\n",
    "```\n",
    "epiclass DREAMtoMD\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methylation density profiles can be generated from raw DREAMing melt data.\n",
    "\n",
    "#### Here, the melting temperature of a given DNA fragment needs to be converted to a methylation density value.\n",
    "\n",
    "To do this, in the case of our locus of interest used in DREAMing (ZNF154), which had 14 internal CpG sites which could influence the DNA fragment melting temperature, we built a linear model to convert the melt temperature to a methylation density value.\n",
    "\n",
    "Any new locus interrogated by DREAMing needs to have a model constructed to convert met temperatures to methylation densities.\n",
    "\n",
    "For ZNF154, the model is summarized in a table\n",
    "```\n",
    "ZNF154DREAMingMeltTempsToMD.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:39:26.365406Z",
     "start_time": "2019-12-06T21:39:26.340462Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'ZNF154DREAMingMeltTempsToMD.csv' does not exist: b'ZNF154DREAMingMeltTempsToMD.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8379fb4e1045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ZNF154DREAMingMeltTempsToMD.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'ZNF154DREAMingMeltTempsToMD.csv' does not exist: b'ZNF154DREAMingMeltTempsToMD.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('ZNF154DREAMingMeltTempsToMD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, the raw melt temperature data will be transformed into a methylation density table\n",
    "\n",
    "The raw DREAMing data table can look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:39:27.006733Z",
     "start_time": "2019-12-06T21:39:26.885894Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>102801_L</th>\n",
       "      <th>102801_H</th>\n",
       "      <th>100296_L</th>\n",
       "      <th>100296_H</th>\n",
       "      <th>102598_L</th>\n",
       "      <th>102598_H</th>\n",
       "      <th>101599_L</th>\n",
       "      <th>101599_H</th>\n",
       "      <th>JFGH_L</th>\n",
       "      <th>...</th>\n",
       "      <th>MUZP-P003_L.1</th>\n",
       "      <th>MUZP-P003_H.1</th>\n",
       "      <th>ESCP-P003_L.1</th>\n",
       "      <th>ESCP-P003_H.1</th>\n",
       "      <th>FOXX-P003_L.1</th>\n",
       "      <th>FOXX-P003_H.1</th>\n",
       "      <th>FELD-P003_L.1</th>\n",
       "      <th>FELD-P003_H.1</th>\n",
       "      <th>DUFF-P003_L.1</th>\n",
       "      <th>DUFF-P003_H.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>copies_loaded</td>\n",
       "      <td>6000</td>\n",
       "      <td>6000</td>\n",
       "      <td>4092</td>\n",
       "      <td>4092</td>\n",
       "      <td>3504</td>\n",
       "      <td>3504</td>\n",
       "      <td>9960</td>\n",
       "      <td>9960</td>\n",
       "      <td>5772</td>\n",
       "      <td>...</td>\n",
       "      <td>606</td>\n",
       "      <td>606</td>\n",
       "      <td>645</td>\n",
       "      <td>645</td>\n",
       "      <td>3568</td>\n",
       "      <td>3568</td>\n",
       "      <td>763</td>\n",
       "      <td>763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>83</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>80.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>83.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>83.2</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>80.6</td>\n",
       "      <td>82.8</td>\n",
       "      <td>81.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.4</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>80.4</td>\n",
       "      <td>81.8</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.4</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>79.8</td>\n",
       "      <td>82.6</td>\n",
       "      <td>81.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>...</td>\n",
       "      <td>81.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>80.4</td>\n",
       "      <td>81.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.6</td>\n",
       "      <td>...</td>\n",
       "      <td>81.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>83.8</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>plate</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>blind a</td>\n",
       "      <td>...</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>date</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>9.12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sample 102801_L 102801_H 100296_L 100296_H 102598_L 102598_H  \\\n",
       "0   copies_loaded     6000     6000     4092     4092     3504     3504   \n",
       "1               1     81.4      NaN     80.6      NaN      NaN      NaN   \n",
       "2               2     80.6      NaN       80     83.2      NaN      NaN   \n",
       "3               3       80      NaN     80.2      NaN     79.6      NaN   \n",
       "4               4     80.6     82.8     81.2      NaN      NaN      NaN   \n",
       "5               5     79.6      NaN     80.2      NaN       80      NaN   \n",
       "6               6     79.6      NaN     81.2      NaN     79.6      NaN   \n",
       "7               7     79.6      NaN      NaN     82.8      NaN      NaN   \n",
       "8               8     80.4     81.8     79.8      NaN      NaN      NaN   \n",
       "9               9     79.8     82.6     81.6      NaN      NaN      NaN   \n",
       "10             10     80.4     81.8      NaN     82.8       80      NaN   \n",
       "11             11     79.8      NaN     79.6      NaN     79.6      NaN   \n",
       "12             12       81      NaN       80     83.8       80      NaN   \n",
       "13          plate  blind a  blind a  blind a  blind a  blind a  blind a   \n",
       "14           date     9.12     9.12     9.12     9.12     9.12     9.12   \n",
       "\n",
       "   101599_L 101599_H   JFGH_L  ... MUZP-P003_L.1 MUZP-P003_H.1 ESCP-P003_L.1  \\\n",
       "0      9960     9960     5772  ...           606           606           645   \n",
       "1      79.8      NaN     79.8  ...            80            83          79.8   \n",
       "2      79.4      NaN     79.8  ...            80          83.2          79.8   \n",
       "3      79.6      NaN       80  ...            80           NaN          79.8   \n",
       "4      79.6      NaN     80.2  ...            80           NaN          79.8   \n",
       "5      79.6      NaN      NaN  ...            80           NaN          79.8   \n",
       "6      79.8      NaN     79.6  ...            80           NaN          79.8   \n",
       "7      79.6      NaN     80.4  ...            81           NaN          79.8   \n",
       "8      79.4      NaN     79.4  ...            81           NaN          79.8   \n",
       "9      79.8      NaN     79.8  ...          81.4           NaN          79.8   \n",
       "10     79.6      NaN     80.6  ...          81.4           NaN          79.8   \n",
       "11     79.6      NaN     79.8  ...           NaN           NaN          79.8   \n",
       "12     79.8      NaN     80.2  ...           NaN           NaN           NaN   \n",
       "13  blind a  blind a  blind a  ...    validation    validation    validation   \n",
       "14     9.12     9.12     9.12  ...          1.03          1.03          1.03   \n",
       "\n",
       "   ESCP-P003_H.1 FOXX-P003_L.1 FOXX-P003_H.1 FELD-P003_L.1 FELD-P003_H.1  \\\n",
       "0            645          3568          3568           763           763   \n",
       "1            NaN          79.8           NaN            80           NaN   \n",
       "2            NaN          79.8           NaN            80           NaN   \n",
       "3            NaN          79.8           NaN            80           NaN   \n",
       "4            NaN            80           NaN            80           NaN   \n",
       "5            NaN            80           NaN            80           NaN   \n",
       "6            NaN            80           NaN            80           NaN   \n",
       "7            NaN          80.2           NaN            80           NaN   \n",
       "8            NaN          80.2           NaN            80           NaN   \n",
       "9            NaN          80.2           NaN            80           NaN   \n",
       "10           NaN            81           NaN            80           NaN   \n",
       "11           NaN          81.2           NaN            80           NaN   \n",
       "12           NaN          81.4           NaN            80           NaN   \n",
       "13    validation    validation    validation    validation    validation   \n",
       "14          1.03          1.03          1.03          1.03          1.03   \n",
       "\n",
       "   DUFF-P003_L.1 DUFF-P003_H.1  \n",
       "0            NaN           NaN  \n",
       "1            NaN           NaN  \n",
       "2            NaN           NaN  \n",
       "3            NaN           NaN  \n",
       "4            NaN           NaN  \n",
       "5            NaN           NaN  \n",
       "6            NaN           NaN  \n",
       "7            NaN           NaN  \n",
       "8            NaN           NaN  \n",
       "9            NaN           NaN  \n",
       "10           NaN           NaN  \n",
       "11           NaN           NaN  \n",
       "12           NaN           NaN  \n",
       "13    validation    validation  \n",
       "14           NaN           NaN  \n",
       "\n",
       "[15 rows x 499 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('20190211-DREAMing_well_melt_temps_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns:\n",
    "1. Sample\n",
    "\n",
    "    row labels:\n",
    "    \n",
    "    **copies_loaded** --> number of genomic copies loaded into the DREAMing assay for a given sample.\n",
    "    \n",
    "    **1 - 12** --> well number in DREAMing assay for given sample and the melt peak temperature recorded for that well. In these assays, a full row of 12 wells across a 96-well plaste was used for each sample in a DREAMing assay. More wells and thus more rows in the table can be added.\n",
    "    \n",
    "    **plate, date, etc** --> additional rows with other sample information can be added but is not required. For example name of plate or date the DREAMing assay wus run.\n",
    "*** \n",
    "\n",
    "2. sample_L, samples_H\n",
    "\n",
    "    Each sample has two columns, **L** and **H**.\n",
    "    \n",
    "    In these DREAMing assays, up to two melt peaks are recorded for a given well. One is the peak to the right of the melt trace and is the **Lower** melt peak, and the peak farthest to the left is the **Higher** melt temperature peak (and also the DNA fragment with the highest methylation density detected in that particular well.\n",
    "***\n",
    "Replicate DREAMing assays of samples can be recorded under the same naming scheme (sample_L, sample_H) and the melt peaks and copies_loaded for these replicates will be combined. The copies loaded will not be double counted for a single L/H sample column pair.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, the number of CpG sites affecting the melt temperatures needs to be indicated\n",
    "\n",
    "For our ZNF154 locus of interest targeted in DREAMing, this was 14 internal CpG sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The command (from the command line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "epiclass DREAMtoMD -i DREAMing_well_melt_temps_raw.csv -temps ZNF154DREAMingMeltTempsToMD.csv -cpg 14 > log.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard output can be collected and will look something like this:\n",
    "```\n",
    "cat log.txt\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------\n",
    "Time:2019-12-06_14-54\n",
    "#--------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------\n",
    "Command:\n",
    "['/miniconda3/envs/epiclass/bin/epiclass', 'DREAMtoMD', '-i', 'DREAMing_well_melt_temps_raw.csv', '-temps', '../ZNF154DREAMingMeltTempsToMD.csv', '-cpg', '14', '--input2bg']\n",
    "Args:\n",
    "Namespace(cmd='DREAMtoMD', includedRows='Sample,copies_loaded', input='DREAMing_well_melt_temps_raw.csv', input2bg=True, numberCpGs=14, output=None, poisson=False, tempResolution=0.2, tempsToMDs='../ZNF154DREAMingMeltTempsToMD.csv', verbose=0)\n",
    "#--------------------------------------------------------------------------\n",
    "DREAMtoMD:\n",
    "Converting DREAMing_well_melt_temps_raw to methylation density table DREAMtoMD.DT.2019-12-06_14-54.csv.\n",
    " \n",
    "DREAMtoMD.DT.2019-12-06_14-54.csv created.\n",
    " \n",
    "DREAMtoMD complete.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DREAMtoMD.DT looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:39:28.777782Z",
     "start_time": "2019-12-06T21:39:28.719307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numU</th>\n",
       "      <th>numM</th>\n",
       "      <th>MD</th>\n",
       "      <th>100250</th>\n",
       "      <th>100292</th>\n",
       "      <th>100296</th>\n",
       "      <th>100442</th>\n",
       "      <th>100626</th>\n",
       "      <th>100654</th>\n",
       "      <th>100662</th>\n",
       "      <th>...</th>\n",
       "      <th>SDFG</th>\n",
       "      <th>TFLK</th>\n",
       "      <th>VCTD-P001</th>\n",
       "      <th>VCTD-P002</th>\n",
       "      <th>VCTD-P003</th>\n",
       "      <th>WHPA</th>\n",
       "      <th>WQHT</th>\n",
       "      <th>WWZX</th>\n",
       "      <th>XCVB</th>\n",
       "      <th>ZXCV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9579.0</td>\n",
       "      <td>39289.0</td>\n",
       "      <td>7241.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>9849.0</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1937.0</td>\n",
       "      <td>4986.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3946.0</td>\n",
       "      <td>9365.0</td>\n",
       "      <td>6015.0</td>\n",
       "      <td>3057.0</td>\n",
       "      <td>2307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    numU  numM    MD  100250   100292  100296  100442  100626  100654  100662  \\\n",
       "0     14     0  0.00  9579.0  39289.0  7241.0   468.0  9849.0  1564.0   747.0   \n",
       "1     13     1  0.07     6.0      0.0     9.0     0.0     3.0     3.0    11.0   \n",
       "2     12     2  0.14    10.0     18.0     7.0     0.0     9.0     1.0     0.0   \n",
       "3     11     3  0.21     2.0      5.0     2.0     0.0     4.0     1.0     0.0   \n",
       "4     10     4  0.28     2.0      3.0     3.0     0.0     2.0     0.0     1.0   \n",
       "5      9     5  0.35     2.0      1.0     7.0     0.0     3.0     2.0     0.0   \n",
       "6      8     6  0.42     0.0      0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "7      7     7  0.49     0.0      0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "8      6     8  0.56     0.0      1.0     1.0     0.0     0.0     0.0     0.0   \n",
       "9      5     9  0.63     1.0      0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "10     4    10  0.70     0.0      0.0     0.0     0.0     1.0     0.0     0.0   \n",
       "11     3    11  0.77     1.0      1.0     0.0     0.0     0.0     0.0     0.0   \n",
       "12     2    12  0.84     0.0      1.0     3.0     0.0     1.0     0.0     0.0   \n",
       "13     1    13  0.91     0.0      0.0     1.0     0.0     0.0     0.0     0.0   \n",
       "14     0    14  1.00     0.0      0.0     2.0     0.0     1.0     0.0     0.0   \n",
       "\n",
       "    ...    SDFG    TFLK  VCTD-P001  VCTD-P002  VCTD-P003    WHPA    WQHT  \\\n",
       "0   ...  1937.0  4986.0      349.0      487.0       25.0  3946.0  9365.0   \n",
       "1   ...     2.0     2.0        4.0       15.0        0.0     1.0    19.0   \n",
       "2   ...     1.0     1.0        2.0        0.0        1.0     1.0    14.0   \n",
       "3   ...     1.0     0.0        0.0        2.0        1.0     0.0     4.0   \n",
       "4   ...     0.0     0.0        0.0        2.0        0.0     0.0     1.0   \n",
       "5   ...     0.0     0.0        0.0        2.0        1.0     0.0     2.0   \n",
       "6   ...     0.0     0.0        0.0        1.0        0.0     0.0     0.0   \n",
       "7   ...     2.0     0.0        0.0        0.0        0.0     0.0     0.0   \n",
       "8   ...     0.0     0.0        0.0        1.0        0.0     0.0     1.0   \n",
       "9   ...     0.0     0.0        0.0        1.0        0.0     0.0     0.0   \n",
       "10  ...     0.0     0.0        1.0        1.0        0.0     0.0     1.0   \n",
       "11  ...     1.0     0.0        1.0        1.0        0.0     0.0     0.0   \n",
       "12  ...     1.0     4.0        0.0        5.0        1.0     0.0     0.0   \n",
       "13  ...     1.0     1.0        1.0        1.0        1.0     0.0     0.0   \n",
       "14  ...     4.0     2.0        4.0        0.0        0.0     0.0     0.0   \n",
       "\n",
       "      WWZX    XCVB    ZXCV  \n",
       "0   6015.0  3057.0  2307.0  \n",
       "1      1.0     1.0     2.0  \n",
       "2      2.0     0.0     2.0  \n",
       "3      0.0     0.0     0.0  \n",
       "4      0.0     0.0     2.0  \n",
       "5      1.0     1.0     2.0  \n",
       "6      1.0     0.0     0.0  \n",
       "7      1.0     1.0     0.0  \n",
       "8      4.0     0.0     1.0  \n",
       "9      4.0     0.0     0.0  \n",
       "10     2.0     0.0     0.0  \n",
       "11     3.0     1.0     1.0  \n",
       "12     5.0     7.0     3.0  \n",
       "13     4.0     6.0     7.0  \n",
       "14     1.0     3.0     4.0  \n",
       "\n",
       "[15 rows x 113 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('vignette/DREAMtoMD.DT.2019-12-06_14-54.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "columns:\n",
    "\n",
    "1. numU --> number of unmethylated CpG sites covered by the read/read-pair (but not by the insert)\n",
    "***\n",
    "2. numM --> number of methylated CpG sites covered by the read/read-pair (but not by the insert)\n",
    "***\n",
    "3. MD --> the determined methylatio density of the read/read-pair (numM / numM + numU)\n",
    "***\n",
    "4. Samples and tabularized counts of epialleles with different methylation densities\n",
    "***\n",
    "\n",
    "Note that this is interogating a specific locus with primers, so \"read\" positional information is not needed.\n",
    "\n",
    "***\n",
    "<p style=\"color:red;\"> Important:\n",
    "    \n",
    "Here the command **--input2bg** was used. This considered the background targets loaded into the DREAMing assay as unmethylated DNA fragments that make up part of the background, and places these counts into the MD=0 counts of epialleles.\n",
    "\n",
    "This is an optional argument, but for the purposes of visualzing the adundance of rare heterogeneously methylated fragments, this is useful.\n",
    "\n",
    "Without input2bg, only epialleles with recorded melt temperatures are kept. So this could be useful to visualize just the methylated epialleles. Furthermore, it is suggested to set the counts of all MD=0 epialleles to zero in order to just visualize and assess methylated epialleles.\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Figures in manuscript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "epiclass MDBC\n",
    "```\n",
    "\n",
    "\n",
    "MDBC:\n",
    "**\"Methylation Density Binary Classifier\"**\n",
    "\n",
    "This subcommand is used to return optimal methylation density and epiallelic fraction cutoffs in addition to a variety of different data visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> A. RRBS Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A READtoMD.DT table was generated using fastq data from WBC, Ovarian cancer, and Normal Ovarian tissue samples.\n",
    "```\n",
    "READtoMD.RRBS.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:39:30.310594Z",
     "start_time": "2019-12-06T21:39:30.270039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>interval_start</th>\n",
       "      <th>interval_stop</th>\n",
       "      <th>methSeqLength</th>\n",
       "      <th>methSeqStart</th>\n",
       "      <th>methSeqStop</th>\n",
       "      <th>numM</th>\n",
       "      <th>numU</th>\n",
       "      <th>MD</th>\n",
       "      <th>FE-0083_ABC00612_BuffyCoat</th>\n",
       "      <th>...</th>\n",
       "      <th>IC-2016_CU_OC09_Ovarian_Normal</th>\n",
       "      <th>IC-2016_CU_OC10_BuffyCoat</th>\n",
       "      <th>IC-2016_CU_OC10_Ovarian_Cancer</th>\n",
       "      <th>IC-2016_CU_OC10_Ovarian_Normal</th>\n",
       "      <th>IC-2016_CU_OC11_BuffyCoat</th>\n",
       "      <th>IC-2016_CU_OC11_Ovarian_Cancer</th>\n",
       "      <th>IC-2016_CU_OC11_Ovarian_Normal</th>\n",
       "      <th>IC-2016_CU_OC13_BuffyCoat</th>\n",
       "      <th>IC-2016_CU_OC13_Ovarian_Cancer</th>\n",
       "      <th>IC-2016_CU_OC13_Ovarian_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>195</td>\n",
       "      <td>58219929</td>\n",
       "      <td>58220124</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>179</td>\n",
       "      <td>58219945</td>\n",
       "      <td>58220124</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>51</td>\n",
       "      <td>58219951</td>\n",
       "      <td>58220002</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>97</td>\n",
       "      <td>58219951</td>\n",
       "      <td>58220051</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>51</td>\n",
       "      <td>58219952</td>\n",
       "      <td>58220003</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>839</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>49</td>\n",
       "      <td>58220721</td>\n",
       "      <td>58220770</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>142</td>\n",
       "      <td>58220726</td>\n",
       "      <td>58220868</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>841</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>58</td>\n",
       "      <td>58220731</td>\n",
       "      <td>58220789</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>842</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>95</td>\n",
       "      <td>58220740</td>\n",
       "      <td>58220835</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>843</td>\n",
       "      <td>chr19</td>\n",
       "      <td>58220000</td>\n",
       "      <td>58220800</td>\n",
       "      <td>51</td>\n",
       "      <td>58220789</td>\n",
       "      <td>58220840</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>844 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chr  interval_start  interval_stop  methSeqLength  methSeqStart  \\\n",
       "0    chr19        58220000       58220800            195      58219929   \n",
       "1    chr19        58220000       58220800            179      58219945   \n",
       "2    chr19        58220000       58220800             51      58219951   \n",
       "3    chr19        58220000       58220800             97      58219951   \n",
       "4    chr19        58220000       58220800             51      58219952   \n",
       "..     ...             ...            ...            ...           ...   \n",
       "839  chr19        58220000       58220800             49      58220721   \n",
       "840  chr19        58220000       58220800            142      58220726   \n",
       "841  chr19        58220000       58220800             58      58220731   \n",
       "842  chr19        58220000       58220800             95      58220740   \n",
       "843  chr19        58220000       58220800             51      58220789   \n",
       "\n",
       "     methSeqStop  numM  numU   MD  FE-0083_ABC00612_BuffyCoat  ...  \\\n",
       "0       58220124     0    12  0.0                           0  ...   \n",
       "1       58220124     0    10  0.0                           0  ...   \n",
       "2       58220002     0     2  0.0                           0  ...   \n",
       "3       58220051     0     3  0.0                           0  ...   \n",
       "4       58220003     0     2  0.0                           0  ...   \n",
       "..           ...   ...   ...  ...                         ...  ...   \n",
       "839     58220770     0     2  0.0                           0  ...   \n",
       "840     58220868     3     2  0.6                           0  ...   \n",
       "841     58220789     3     0  1.0                           0  ...   \n",
       "842     58220835     0     4  0.0                           0  ...   \n",
       "843     58220840     2     0  1.0                           0  ...   \n",
       "\n",
       "     IC-2016_CU_OC09_Ovarian_Normal  IC-2016_CU_OC10_BuffyCoat  \\\n",
       "0                                 0                          0   \n",
       "1                                 0                          0   \n",
       "2                                 0                          0   \n",
       "3                                 0                          0   \n",
       "4                                 0                          0   \n",
       "..                              ...                        ...   \n",
       "839                               0                          0   \n",
       "840                               0                          0   \n",
       "841                               0                          0   \n",
       "842                               0                          0   \n",
       "843                               0                          0   \n",
       "\n",
       "     IC-2016_CU_OC10_Ovarian_Cancer  IC-2016_CU_OC10_Ovarian_Normal  \\\n",
       "0                                 0                               0   \n",
       "1                                 0                               0   \n",
       "2                                 0                               0   \n",
       "3                                 0                               0   \n",
       "4                                 0                               0   \n",
       "..                              ...                             ...   \n",
       "839                               0                               0   \n",
       "840                               0                               0   \n",
       "841                               0                               0   \n",
       "842                               0                               0   \n",
       "843                               0                               0   \n",
       "\n",
       "     IC-2016_CU_OC11_BuffyCoat  IC-2016_CU_OC11_Ovarian_Cancer  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "..                         ...                             ...   \n",
       "839                          0                               0   \n",
       "840                          0                               0   \n",
       "841                          0                               0   \n",
       "842                          0                               0   \n",
       "843                          0                               0   \n",
       "\n",
       "     IC-2016_CU_OC11_Ovarian_Normal  IC-2016_CU_OC13_BuffyCoat  \\\n",
       "0                                 0                          0   \n",
       "1                                 0                          0   \n",
       "2                                 0                          0   \n",
       "3                                 0                          0   \n",
       "4                                 0                          0   \n",
       "..                              ...                        ...   \n",
       "839                               0                          0   \n",
       "840                               0                          0   \n",
       "841                               0                          0   \n",
       "842                               0                          0   \n",
       "843                               0                          0   \n",
       "\n",
       "     IC-2016_CU_OC13_Ovarian_Cancer  IC-2016_CU_OC13_Ovarian_Normal  \n",
       "0                                 0                               0  \n",
       "1                                 0                               0  \n",
       "2                                 0                               0  \n",
       "3                                 0                               0  \n",
       "4                                 0                               0  \n",
       "..                              ...                             ...  \n",
       "839                               0                               0  \n",
       "840                               0                               0  \n",
       "841                               0                               0  \n",
       "842                               0                               0  \n",
       "843                               0                               0  \n",
       "\n",
       "[844 rows x 57 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('vignette/READtoMD.DT.RRBS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalized sample read fraction for ovarian cancer, normal ovarian, and WBC tissues\n",
    "\n",
    "Figure S3 example:\n",
    "\n",
    "```\n",
    "epiclass MDBC -i READtoMD.DT.RRBS.csv -a Ovarian_Cancer -b BuffyCoat --ignoreCountsummary --ignoreEFsummary --casesEfPlot --controlsEfPlot\n",
    "```\n",
    "\n",
    "-a -b\n",
    "\n",
    "names of case (-a) and control (-b) samples. Here, using regex to select samples that contain those keys. But can also pass a space-separated list of sample names to either argument.\n",
    "\n",
    "--ignoreCountsummary\n",
    "--ignoreEFsummary\n",
    "\n",
    "skip doing the full MDBC analysis.\n",
    "\n",
    "--casesEfPlot --controlsEfPlot\n",
    "\n",
    "return sample distributions of normalized read fractions. Because this is RRBS data, and duplicates were not removed (because RRBS is an enrichment targeted sequencing method), do not know definitely the read counts. But can compute relative fractions of reads with different methylation densities.\n",
    "\n",
    "\n",
    "Alternatively:\n",
    "```\n",
    "epiclass MDBC -i READtoMD.DT.RRBS.csv -a Ovarian_Normal -b \" \" --ignoreCountsummary --ignoreEFsummary --casesEfPlot --controlsEfPlot\n",
    "```\n",
    "\n",
    "Here, can just look at one set of samples (-a Ovarian_Normal) without needing a second sample set. But do need to pass an \"empty list\" (-b \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:27:40.210472Z",
     "start_time": "2019-12-06T20:27:40.077164Z"
    }
   },
   "source": [
    "![example](vignette/figures/MDBC.RRBS.CASES-READ-FRACs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <p style=\"color:red;\"> B. Simulations with RRBS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to:\n",
    "\n",
    "**\"RRBS_simulated_dilutions.ipynb\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T20:35:46.786512Z",
     "start_time": "2019-12-06T20:35:46.783852Z"
    }
   },
   "source": [
    "### <p style=\"color:red;\"> C. DREAMing plasma Data\n",
    "\n",
    "##### Here, we have exact counts of cfDNA fragments with different methylation density cutoffs in each sample.\n",
    "\n",
    "##### Because different equivalents of plasma were assessed for each sample, we can normalize the samples by mLs of plasma.\n",
    "\n",
    "\n",
    "Use the **--fractions** option with the file:\n",
    "```\n",
    "fractions.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:39:31.779416Z",
     "start_time": "2019-12-06T21:39:31.762785Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samples</th>\n",
       "      <th>fractions</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>JKLR</td>\n",
       "      <td>0.97</td>\n",
       "      <td>cases 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FLAB</td>\n",
       "      <td>0.89</td>\n",
       "      <td>cases 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>JGLR</td>\n",
       "      <td>0.86</td>\n",
       "      <td>cases 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>JFGH</td>\n",
       "      <td>0.78</td>\n",
       "      <td>cases 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>GKHG</td>\n",
       "      <td>0.95</td>\n",
       "      <td>cases 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>102795</td>\n",
       "      <td>0.51</td>\n",
       "      <td>controls 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>100292</td>\n",
       "      <td>0.64</td>\n",
       "      <td>controls 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>102126</td>\n",
       "      <td>0.64</td>\n",
       "      <td>controls 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>100662</td>\n",
       "      <td>0.72</td>\n",
       "      <td>controls 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>102199</td>\n",
       "      <td>0.60</td>\n",
       "      <td>controls 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    samples  fractions         set\n",
       "0      JKLR       0.97     cases 1\n",
       "1      FLAB       0.89     cases 1\n",
       "2      JGLR       0.86     cases 1\n",
       "3      JFGH       0.78     cases 1\n",
       "4      GKHG       0.95     cases 1\n",
       "..      ...        ...         ...\n",
       "98   102795       0.51  controls 2\n",
       "99   100292       0.64  controls 2\n",
       "100  102126       0.64  controls 2\n",
       "101  100662       0.72  controls 2\n",
       "102  102199       0.60  controls 2\n",
       "\n",
       "[103 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('vignette/fractions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important columns here are the \"samples\" and the \"fractions\"\n",
    "\n",
    "Here, \"fractions\" is the equivalent mLs of plasma assessed for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Training plasma set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "epiclass MDBC -i DREAMtoMD.DT.2019-12-06_14-54.csv -a JKLR FLAB JGLR JFGH GKHG JHPP WHPA HKLP FQTR JUTM TFLK JQRT WQHT QWID QWER POIU ASDF GFUR ZXCV HJKL REWQ SDFG XCVB JGIS WWZX KRUK -b 101086 102801 100626 101425 145355 100296 101599 106732 106853 109195 109286 109336 110164 113493 114250 121203 121274 123154 123874 124110 127216 128141 129125 129499 130752 131004 139606 103971 101997 102073 106401 106136 109837 121624 102060 103782 114482 109604 101968 102919 100654 --casesReadCountPlot  --controlsReadCountPlot --readcountDistributionPlot --readcountheatmaps --sampleValsAtMD 0.0 0.60 0.95 --maxCutoff 100.0 --fractions fractions.csv > log.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A breakdown:\n",
    "\n",
    "First run will store sample values in MDBC_H5DF.h5 file for faster access to data in subsequent runs.\n",
    "\n",
    "Prints to standard output the optimal methylation density cutoffs for the normalized read count epiallelic fraction (reads/mL of plasma), or the normalized EF (this is the fraction of reads in a sample, and appropriate for sequencing datasets but not necessarily for DREAMing data).\n",
    "\n",
    "Also returned is the\n",
    "```READ-COUNT-SUMMARY.csv```\n",
    "which contains the optimal read count cutoff for each MD cutoff and the corresponding TPR and 1 - FPR.\n",
    "\n",
    "And \n",
    "\n",
    "\n",
    "arguments:\n",
    "\n",
    "1. -i --> the DREAMtoMD table with the input DNA included as background\n",
    "2. -a/-b --> the training set cases and controls, which are in the DREAMtoMD table\n",
    "3. --casesReadCountPlot  --controlsReadCountPlot --> stacked bar plots showing the normalized read counts of different epialleles in each sample. (Figure S8)\n",
    "4. --readcountDistributionPlot --> Overall distribution of epiallele frequencies in the cases and controls (Figures 3A)\n",
    "5. --readcountheatmaps --> TPR, FPR, and TPR - FPR heatmaps of different methylation density and epialleleic fraction cutoffs (Figures S10 and S12)\n",
    "6. --sampleValsAtMD 0.0 0.60 0.95 --> return boxplots, ROC curves, and tables of sample values for selected MD cutoffs of interest (0.0, 0.6, and 0.95) (Figure S11)\n",
    "7. --maxCutoff 100.0 --> because we're looking at read counts, changes the read count cutoff range used for the TPR/FPR heatmaps for better visualization\n",
    "8. --fractions fractions.csv --> normalized the sample read counts to mLs of plasma (values in \"fractions\" column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard output:\n",
    "```\n",
    "#--------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------\n",
    "Time:2019-12-06_16-09\n",
    "#--------------------------------------------------------------------------\n",
    "#--------------------------------------------------------------------------\n",
    "Command:\n",
    "['/miniconda3/envs/epiclass/bin/epiclass', 'MDBC', '-i', 'DREAMtoMD.DT.2019-12-06_14-54.csv', '-a', 'JKLR', 'FLAB', 'JGLR', 'JFGH', 'GKHG', 'JHPP', 'WHPA', 'HKLP', 'FQTR', 'JUTM', 'TFLK', 'JQRT', 'WQHT', 'QWID', 'QWER', 'POIU', 'ASDF', 'GFUR', 'ZXCV', 'HJKL', 'REWQ', 'SDFG', 'XCVB', 'JGIS', 'WWZX', 'KRUK', '-b', '101086', '102801', '100626', '101425', '145355', '100296', '101599', '106732', '106853', '109195', '109286', '109336', '110164', '113493', '114250', '121203', '121274', '123154', '123874', '124110', '127216', '128141', '129125', '129499', '130752', '131004', '139606', '103971', '101997', '102073', '106401', '106136', '109837', '121624', '102060', '103782', '114482', '109604', '101968', '102919', '100654', '--casesReadCountPlot', '--controlsReadCountPlot', '--readcountDistributionPlot', '--readcountheatmaps', '--sampleValsAtMD', '0.0', '0.60', '0.95', '--maxCutoff', '100.0', '--fractions', '../fractions.csv']\n",
    "Args:\n",
    "Namespace(EfDistributionPlot=False, EfEachMD=False, Efheatmaps=False, MDcutoffs=None, cases=['JKLR', 'FLAB', 'JGLR', 'JFGH', 'GKHG', 'JHPP', 'WHPA', 'HKLP', 'FQTR', 'JUTM', 'TFLK', 'JQRT', 'WQHT', 'QWID', 'QWER', 'POIU', 'ASDF', 'GFUR', 'ZXCV', 'HJKL', 'REWQ', 'SDFG', 'XCVB', 'JGIS', 'WWZX', 'KRUK'], casesEfPlot=False, casesReadCountPlot=True, cmd='MDBC', controls=['101086', '102801', '100626', '101425', '145355', '100296', '101599', '106732', '106853', '109195', '109286', '109336', '110164', '113493', '114250', '121203', '121274', '123154', '123874', '124110', '127216', '128141', '129125', '129499', '130752', '131004', '139606', '103971', '101997', '102073', '106401', '106136', '109837', '121624', '102060', '103782', '114482', '109604', '101968', '102919', '100654'], controlsEfPlot=False, controlsReadCountPlot=True, fileTag=None, fractions='../fractions.csv', hdf_label=None, ignoreCountsummary=False, ignoreEFsummary=False, input='DREAMtoMD.DT.2019-12-06_14-54.csv', maxCutoff=100.0, optimalMDEf=False, optimalMDreadcounts=False, output=None, readcountDistributionPlot=True, readcountheatmaps=True, readcountsEachMD=False, sampleAveMethTable=False, sampleValsAtMD=[0.0, 0.6, 0.95], totalEf=False, totalEfPlot=False, totalReadCountPlot=False, totalReadCounts=False, verbose=0)\n",
    "#--------------------------------------------------------------------------\n",
    "MDBC Analysis\n",
    "\n",
    " Generating performance summary for each MD using normalized read counts...\n",
    " Appending sample read count and fraction values for MD cutoff 0.0 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " \n",
    "  key = self.storeSampleValuesPerMD[m][i]\n",
    " Appending sample read count and fraction values for MD cutoff 0.05 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.1 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.15 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.2 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.25 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.3 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.35 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.4 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.45 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.5 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.55 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.6 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.65 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.7 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.75 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.8 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.85 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.9 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 0.95 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " Appending sample read count and fraction values for MD cutoff 1.0 to HDF5 file MDBC_H5DF.2019-12-06_14-54.h5\n",
    " \n",
    " Optimal MD cutoff (read counts) = 0.6\n",
    " p-val (cases vs controls) = 0.018868401440273255\n",
    " AUC = 0.6712007504690432\n",
    "\n",
    " Returning cases read counts for each MD barplot: MDBC.2019-12-06_14-54.CASES-READS-COUNTS.png\n",
    " Returning controls read counts for each MD barplot: MDBC.2019-12-06_14-54.CONTROLS-READS-COUNTS.png\n",
    " \n",
    " Returning sample values for MD cutoff = 0.0: MDBC.2019-12-06_14-54.0.0_MD-COUNTS/EFS_VALS.csv\n",
    " normalized read count = p-val (cases vs controls) = 0.7186529876661425\n",
    " normalized read count AUC = 0.526266416510319\n",
    " \n",
    " Returning sample values for MD cutoff = 0.6: MDBC.2019-12-06_14-54.0.6_MD-COUNTS/EFS_VALS.csv\n",
    " normalized read count = p-val (cases vs controls) = 0.018868401440273255\n",
    " normalized read count AUC = 0.6712007504690432\n",
    " \n",
    " Returning sample values for MD cutoff = 0.95: MDBC.2019-12-06_14-54.0.95_MD-COUNTS/EFS_VALS.csv\n",
    " normalized read count = p-val (cases vs controls) = 0.020560739563001446\n",
    " normalized read count AUC = 0.6688555347091932\n",
    "\n",
    " Returning distribution of reads for each MD histogram: MDBC.2019-12-06_14-54.READ-DISTR.png\n",
    " Returning TPR/FPR/TPR-FPR heatmaps using read counts: MDBC.2019-12-06_14-54.COUNT-*.png\n",
    " \n",
    "Files stored in: vignette/trainingSet\n",
    " \n",
    "MDBC analysis completed.\n",
    "```\n",
    "***\n",
    "For DREAMing, the read fraction (EF) cutoffs should be ignored. The read count cutoffs are of interest. Optimal read count methylation density cutoff is 0.6. The READ-COUNT-SUMMARY.csv returned has the corresponding read count epiallelic cutoffs and TPR and 1-FPRs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training plasma set, only epialleles >20% methylated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can visualize just the epialleles above a certain methylation value.\n",
    "\n",
    "Used ```DREAMtoMD.DT.2019-12-06_14-54.bg2zero.csv``` where MD read counts of 0.0%, 0.07%, 0.14% were changed to zero\n",
    "\n",
    "```\n",
    "epiclass MDBC -i DREAMtoMD.DT.2019-12-06_14-54.bg2zero.csv -a JKLR FLAB JGLR JFGH GKHG JHPP WHPA HKLP FQTR JUTM TFLK JQRT WQHT QWID QWER POIU ASDF GFUR ZXCV HJKL REWQ SDFG XCVB JGIS WWZX KRUK -b 101086 102801 100626 101425 145355 100296 101599 106732 106853 109195 109286 109336 110164 113493 114250 121203 121274 123154 123874 124110 127216 128141 129125 129499 130752 131004 139606 103971 101997 102073 106401 106136 109837 121624 102060 103782 114482 109604 101968 102919 100654 --ignoreCountsummary --ignoreEFsummary --casesReadCountPlot  --controlsReadCountPlot --fractions fractions.csv > log.txt\n",
    "```\n",
    "***\n",
    "The read counts plots here used to make Figure S8B\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-06T21:31:36.586860Z",
     "start_time": "2019-12-06T21:31:36.584131Z"
    }
   },
   "source": [
    "### 3. Validation plasma set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "epiclass MDBC -i DREAMtoMD.DT.2019-12-06_14-54.csv -a ASCS-P001 DJNG-P001 VCTD-P001 MUZP-P001 ESCP-P001 FOXX-P001 FELD-P001 DUFF-P001 ASCS-P002 DJNG-P002 VCTD-P002 MUZP-P002 ESCP-P002 FOXX-P002 FELD-P002 DUFF-P002 ASCS-P003 DJNG-P003 VCTD-P003 MUZP-P003 ESCP-P003 FOXX-P003 FELD-P003 DUFF-P003 -b 106133 102598 102760 106126 100250 100442 103197 102795 100292 102126 100662 102199 --casesReadCountPlot  --controlsReadCountPlot --readcountDistributionPlot --readcountheatmaps --sampleValsAtMD 0.0 0.60 0.95 --fractions fractions.csv > log.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the outputs\n",
    "\n",
    "Finally, Figures 3B, 4B, combined ROC curves, and the results of Table 1 can be generated using the ```READ-COUNT-SUMMARY.csv```, the ```0.0_MD-COUNTS_VALS.csv```, the ```0.6_MD-COUNTS_VALS.csv```, and the ```0.95_MD-COUNTS_VALS.csv``` files from either the trainingSet or the validationSet.\n",
    "\n",
    "Refer to:\n",
    "\n",
    "**\"MDBC_plasma_figures.ipynb\"**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
